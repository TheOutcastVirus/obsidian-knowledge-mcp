## Introduction
Hey there, I'm Vikram Kommera. I have been taking notes using [Obsidian](https://obsidian.md/) so far this quarter. I have typed my notes in LaTeX using the [LaTeX Suite](https://github.com/artisticat1/obsidian-latex-suite) plugin for Obsidian, which allows me to use shortcuts while typing to keep up during lecture. 

I have taken notes on most proofs and examples during lecture. There may be typos and conceptual mistakes, but I have tried my best to keep this accurate. I hope you can find this useful to study for our final. 

## Lecture Summaries
> This only roughly maps to the lectures we had in class. I took this from out canvas page and linked different notes as a I found them. There are more notes that linked here. See the sidebar for all notes. 
- **Lecture 1:** Introduction. [[Injective, surjective, bijective functions|Injective, surjective, bijective]] [[functions]]. Read sections 0.4 and 0.6.
- **Lecture 2:** More on bijective functions. [[Countable & uncountable sets|Countable and uncountable sets]].
- **Lecture 3:** [[Vectors|Vectors]]. Addition, scalar multiplication. [[Linear subspaces|Vector subspaces]]. [[Linear independence]], [[Linear span|span]], [[basis]], dimension.
- **Lecture 4:** [[Dot product]] and [[cross product]]. [[Cauchy Schwarz Inequality|Cauchy-Schwarz]] and [[Triangle inequality|triangle inequalities]].
- **Lecture 5:** [[Systems of Linear Equations|Systems of linear equations]]. Matrix-vector product. [[Matrix multiplication|Matrix products]]. [[Transpose|Transpose]].
- **Lecture 6:** [[Linear transformations]], projections, reflections, rotations. Matrix of a linear transformation.
- **Lecture 7:** [[Linear transformations#Compositions|Composition of linear transformations]] and [[matrix multiplication]].
- **Lecture 8:** [[Null Spaces|Null space]]. Examples of null spaces. Null space and uniqueness of solutions of linear systems. Row-reduced echelon form.
- **Lecture 9:** [[Echelon form|Pivot and free variables]]. Nullity equals the number of free variables. Basis for null space is obtained from the rref. (In)dependence of columns and vectors in the null space. n+1 vectors in R^n are dependent.
- **Lecture 10:** Column space: Ax=b has solutions only for b in the column space of A. Finding the column space by row-reducing the augumented matrix. Equivalent conditions for columns of A to span, with emphasis on square matrices: rref=I.
- **Lecture 11:** Basis for column space is given by the pivot columns. Rank. Midterm review.
- **Lecture 12:** [[Null Spaces|Rank-nullity theorem]]. [[Matrix inverses|Invertible matrices]]. Finding the inverse by computing rref[A|I].
- **Lecture 13:** [[Determinant|Determinants]] and invertible matrices. Propreties of determinants stated (no proofs): Expansion along columns and rows. Determinants and row operations. Geometric interpretation of determinants.
- **Lecture 14/15:** More on row operations and [[Determinant|determinants]]. Determinants are alternating and multilinear. Proofs by induction starting from expansion along the first row.
- **Lecture 16:** Uniqueness of the determinant as an alternatating, multilinear, normalized function on the set of n x n matrices. Expansion along rows and columns gives the same answer. [[Determinant|Determinant]] of a product is the product of determinants.
- **Lecture 16:** Determinants and areas/volumes of regions in R^2/R^3.
- **Lecture 17:** [[Orthogonality|Orthogonal]] complements. Connections between null spaces of a matrix, transpose, column space, column space of the transpose. Examples.
- **Lecture 18:** Matrix of a projection is A(A^TA)^{-1}A^T. Examples. [[Orthogonality|Orthogonal]] sets. [[Orthogonality|Orthonormal basis]] of a subspace, for an orthonormal basis the matrix of the projection is AA^T. Orthogonal matrices.
- **Lecture 19:** [[Orthogonality#Gram-Schmidt process|Another way of computing the projection]] when an orthonormal basis is given. Finding an orthonormal basis.
- **Lecture 20:** Systems of coordinates. Change of basis matrix. Matrix of a linear transformation with respect to an arbitrary basis. Example: projections onto a plane in R^3.
- **Lecture 21:** [[Similar matrices]]. Midterm review.
- **Lecture 22:** [[Eigenvalues and eigenvectors|Eigenvalues, eigenvectors]]. Characteristic polynomial is det (\lambda I-A). Eigenvalues are roots of the characteristic polynomial, eigenvectors are found by calculating the null space of \lambda I-A. [[Diagonalization|Diagonalizable]] matrices are similar to diagonal matrices where the eigenvalues are on the main diagonal.
- **Lecture 23:** Examples of non-diagonalizable matrices. Distinct eigenvalues implies [[Diagonalization|diagonalizable]]. Characteristic polynomial for 2 x 2 matrix is \lambda^2- Trace \lambda + det. Sum of eigenvalues is the trace, product of eigenvalues is the determinant.
- **Lecture 24:** Complex eigenvalues. A real matrix has eigenvalues in pairs (lambda, lambda conjugate). Symmetric matrices have real eigenvalues. Real symmetric matrices are diagonalizable.
- **Lecture 25:** Examples of orthonormal [[Eigenbasis|eigenbasis]] for symmetric matrices. Quadratic forms. Symmetric matrices associated to quadratic forms. Positive definite, negative definite, semidefinite, indefinite forms.
- **Lecture 25:** Quadratic forms continued: determining the definiteness of the form from the eigenvalues. The cases of 2 x 2 matrices can be read off from the trace and determinant. Examples. What's ahead: abstract vector spaces, abstract linear transformations, etc.